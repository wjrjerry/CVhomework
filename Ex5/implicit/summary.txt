核心思想
Occupancy Network通过学习一个连续的占用函数(Occupancy Function)来表示3D物体。这个函数将任意3D空间点映射到一个0到1之间的值，表示该点是否在物体内部。
如果点在物体内部，输出接近1
如果点在物体外部，输出接近0

网络结构
输入：3D空间中的点坐标(x,y,z)和物体的特征向量 （特征向量可以是图片或者是点云，voxels等等）
输出：该点的占用概率值(0~1之间)
网络主要由全连接层组成，通过条件批归一化(Conditional Batch Normalization)将物体特征融入网络

训练过程
数据准备：从3D模型中采样点对(空间点坐标和对应的占用值)
损失函数：使用二元交叉熵损失，让网络预测的占用值尽量接近真实值
条件信息：可以是图片特征、点云特征等，用于指导重建特定物体

重建过程
对于输入的条件(如图片)，提取特征向量
在3D空间中密集采样点
将这些点输入网络得到占用值
使用Marching Cubes等算法从占用值生成mesh表面

主要优点
连续性：可以在任意分辨率下重建，不受体素网格限制
平滑性：生成的表面通常比较光滑
拓扑自由：可以处理任意拓扑结构的物体
内存效率：不需要存储密集的体素网格

关键技术点
条件批归一化：将物体特征有效地融入网络
多分辨率采样：训练时使用不同尺度的点改善细节
表面提取：使用等值面提取算法得到最终mesh

局限性
计算开销：推理时需要查询大量点的占用值
细节表现：对于非常精细的结构可能不够准确
训练数据：需要大量高质量的3D模型数据